# Learning Objectives
## Lecture 1: Introduction
## Lecture 2: Baselines, Decision Trees
- **Identifying problems for [[Supervised Learning|Supervised Machine Learning]]**
	- a problem can be solved with supervised learning if you have labelled data, where each input in the dataset is paired with an output
	- for example, predicing house prices based on their size and location
- **Differentiating between supervised and [[Unsupervised Learning]]**
	- in supervised learning, model learns from labelled data to make predictions
	- in unsupervised learning, the model works with unlabelled data to find patterns/groupings
		- e.g. clustering customers based on purchasing behaviours
- **Explain ML Terminology**
	- **Features**: inputs or variables used to make predictions (e.g. age, income)
	- **Targets**: the output or variable that the model is trying to predict (e.g. creditworthiness)
	- **Predictions**: the output generated by the model
	- **Training**: the process of teaching a model to make predictions by learning from a dataset
	- **Error**: the difference between the model's prediction and the actual values
- **Differentiate between [[Classification]] and [[Regression]] problems**
	- classification involves predicting a category (spam/not spam), regression involves predicting a continuous value (house prices)
- **Using `DummyClassifier` and `DummyRegressor` as [[Baselines]]**
	- these simple models provide a baseline for comparison
	- `DummyClassifier` might predict most frequent class
	- `DummyRegressor` might predict the mean of the target values
	- establish a minimum performance baseline for more sophisticated models
- explain the `fit` and `predict` paradigm and use `score` method of ML models; 
- broadly describe how decision tree prediction works;
- use `DecisionTreeClassifier` and `DecisionTreeRegressor` to build decision trees using `scikit-learn`; 
- visualize decision trees; 
- explain the difference between parameters and hyperparameters; 
- explain the concept of decision boundaries;
- explain the relation between model complexity and decision boundaries.
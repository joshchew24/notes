# Decision Trees
- [[Tree-based model]]

Learn a binary decision tree to predict the outcome
![[Pasted image 20240118223710.png]]
- note: this example uses discrete/binary features, so the decision threshold is always `0.5`
- decision trees can be created with continuous features, resulting in varying thresholds
## [[Feature Selection]]
- which features are most useful for classification?
- aim to minimize **impurity** at each node
	- lower impurity indicates a more **homogenous** or **pure** set of data points
	- i.e. we aim to create subsets that are more homogenous with respect to the target variable
	- By default, leaf nodes are **pure**
### Criteria to Minimize Impurity
- [[Gini Index]]
- information gain
- cross entropy
## [[Regression]]
- instead of [[Gini Index|gini]], we use other criteria for splitting
	- commonly use [[Mean Squared Error (MSE)]]
- [[sklearn]] supports regression using decision trees with `DecisionTreeRegressor`
## [[Parameters]]
- the best feature to split on
- the threshold for the feature to split on at each node
## [[Hyperparameters]]
### Max Depth
- a super deep decision node may be too closely fitted to the training data
	- i.e. a single unique training data point is serving as the only evidence for a prediction
#### Decision Stump
- a decision tree with only one split (`depth = 1`)
```python
model = DecisionTreeClassifier(max_depth=1)
model.fit(X, y)
display_tree(X.columns, model, counts=True)
```
![[Pasted image 20240118230816.png]]
#### Plot Tree Helper
```python
# Custom function to customize the tree plot and hide values and samples
def custom_plot_tree(tree_model, feature_names=None, class_names=None, **kwargs):
    """
    Customizes and displays a tree plot for a scikit-learn Decision Tree Classifier.

    Parameters:
    - tree (sklearn.tree.DecisionTreeClassifier): The trained Decision Tree Classifier to visualize.
    - width: width of the matplotlib plot in inches 
    - height: height of the matplotlib plot in inches 
    - feature_names (list or None): A list of feature names to label the tree nodes with feature names.
                                    If None, generic feature names will be used.
    - class_names (list or None): A list of class names to label the tree nodes with class names.
                                  If None, generic class names will be used.
    - **kwargs: Additional keyword arguments to be passed to the `sklearn.tree.plot_tree` function.

    Returns:
    - None: The function displays the customized tree plot using Matplotlib.
    
    This function customizes the appearance of a Decision Tree plot generated by the scikit-learn
    `plot_tree` function. It hides both the samples and values in each node of the tree plot
    for improved visualization.
    """    
    plot_tree(tree_model, 
              feature_names=feature_names, 
              class_names=class_names, 
              filled=True, 
              **kwargs)
    
    # Customize the appearance of the text elements for each node
    for text in plt.gca().texts:
        new_text = re.sub('samples = \d+\n', '', text.get_text()) # Hide samples
        text.set_text(new_text) 
    
    plt.show()
```
### Others
- `min_samples_split`
- `min_samples_leaf`
- `max_leaf_nodes`
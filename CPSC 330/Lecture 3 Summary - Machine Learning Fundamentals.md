# Lecture 3 Summary - Machine Learning Fundamentals
## Learning Objectives
- **explain how decision boundaries change with the `max_depth` hyperparameter**
	- decision boundaries in decision trees are determined by conditions set at each node
	- `max_depth` controls maximum depth of the tree
	- deeper trees have more complex decision boundaries, capturing finer details in data
	- too much depth can cause overfitting
- **explain the concept of generalization**
	- a model's ability to perform well on new, unseen data, not just training data
	- captures underlying patterns in data without being too complex/simplistic
- **appropriately [[Data Splitting|split a dataset]] into tran and test sets using `train_test_split` function**
	- `train_test_split` function in [[sklearn]] is  used to divide a dataset into training and testing sets
	- training set used to train the model
	- testing set used to evaluate its performance
	- ensures we are evaluating performance on unseen data
- **explain the difference between train, validation, test, and "deployment" data**
	- **Training Data**: used to fit the model
	- **Validation Data**: used to tune hyperparameters and make decisions about the model (e.g. which features to use)
	- **Test Data**: used to assess model's performance and its ability to generalize to new data
	- **Deployment Data**: real world data encountered by the model after deployment in production environment
- **identify the difference between training error, validation error, and test error**
	- **Training Error**: error the model makes on the data it was trained on
	- **Validation Error**: error during hyperparameter tuning phase on a separate validation set
	- **Test Error**: error when the model is applied to the test set, which reflects its ability to generalize
- **explain cross-validation and use `cross_val_score` and `cross_validate` to calculate cross-validation error**
- **recognize overfitting and/or underfitting by looking at train and test scores**
- **explain why it is generally not possible to get a perfect test score (zero test error) on a supervised learning problem**
- **describe the fundamental tradeoff between training score and the train-test gap**
- **state the golden rule**
- **start to build a standard recipe for supervised learning: train/test split, hyperparameter tuning with cross-validation, test on test set**